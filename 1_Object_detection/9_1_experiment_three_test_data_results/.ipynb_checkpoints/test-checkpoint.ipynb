{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyRdDYkqAKN4"
   },
   "source": [
    "## Before you start\n",
    "\n",
    "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y8cDtxLIBHgQ",
    "outputId": "c5b61b8c-6d66-469d-9d94-7a69fff79f2e"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CjpPg4mGKc1v",
    "outputId": "135c7011-f973-4f9a-f7ad-f29dfde09fbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pravi\\OneDrive\\Desktop\\Pravin\\Study\\Masters\\Research_Project\\code\\10_test-1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3C3EO_2zNChu"
   },
   "source": [
    "## Install YOLOv10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Bf6A7E9glExI"
   },
   "outputs": [],
   "source": [
    "# !pip install -q supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tdSMcABDNKW-",
    "outputId": "ec56e18f-11a0-475e-91e5-792e9d104797"
   },
   "outputs": [],
   "source": [
    "# !pip install -q git+https://github.com/THU-MIG/yolov10.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SaKTSzSWnG7s",
    "outputId": "a8bd10f1-cc74-432a-bac2-64aab9c92c77"
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import supervision as sv\n",
    "# from ultralytics import YOLOv10\n",
    "\n",
    "# model = YOLOv10(f'{HOME}/weights/best.pt')\n",
    "# image = cv2.imread(f'{HOME}/datasets/dataset/test/images/cocci.5.jpg')\n",
    "\n",
    "# results = model(image)[0]\n",
    "\n",
    "# detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "# bounding_box_annotator = sv.BoundingBoxAnnotator()\n",
    "# label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "# annotated_image = bounding_box_annotator.annotate(\n",
    "#     scene=image, detections=detections)\n",
    "# annotated_image = label_annotator.annotate(\n",
    "#     scene=annotated_image, detections=detections)\n",
    "\n",
    "# sv.plot_image(annotated_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUjFBKKqXa-u"
   },
   "source": [
    "## Custom Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D2YkphuiaE7_",
    "outputId": "de75e93e-509b-4b3e-ca4b-295b3c6adf8a"
   },
   "outputs": [],
   "source": [
    "# %cd {HOME}\n",
    "\n",
    "# !yolo task=detect mode=train epochs=1 batch=32 plots=True \\\n",
    "# model={HOME}/weights/yolov10n.pt \\\n",
    "# data={dataset.location}/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from yolov10 import YOLO\n",
    "\n",
    "# # Path to your trained model weights\n",
    "# model_path = 'weights/yolov10n.pt'\n",
    "# model = YOLO(model_path)\n",
    "\n",
    "from ultralytics import YOLOv10\n",
    "model = YOLOv10(f'{HOME}/weights/best.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "def load_images_and_annotations(image_dir, annotation_dir):\n",
    "    images = []\n",
    "    annotations = []\n",
    "\n",
    "    image_files = glob.glob(os.path.join(image_dir, '*.jpg'))\n",
    "    for image_file in image_files:\n",
    "        image = cv2.imread(image_file)\n",
    "        images.append(image)\n",
    "\n",
    "        # Assuming YOLO format annotations in txt files\n",
    "        annotation_file = os.path.join(annotation_dir, os.path.basename(image_file).replace('.jpg', '.txt'))\n",
    "        with open(annotation_file, 'r') as file:\n",
    "            bboxes = [line.strip().split() for line in file.readlines()]\n",
    "            annotations.append(bboxes)\n",
    "\n",
    "    return images, annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(model, images):\n",
    "    predictions = []\n",
    "    for image in images:\n",
    "        results = model.predict(image)\n",
    "        predictions.append(results)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def calculate_metrics(predictions, annotations):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for pred, ann in zip(predictions, annotations):\n",
    "        for bbox in ann:\n",
    "            label = int(bbox[0])\n",
    "            y_true.append(label)\n",
    "            matched = False\n",
    "            for pred_bbox in pred:\n",
    "                pred_label = int(pred_bbox['label'])\n",
    "                if pred_label == label:\n",
    "                    matched = True\n",
    "                    y_pred.append(pred_label)\n",
    "                    break\n",
    "            if not matched:\n",
    "                y_pred.append(-1)  # For unmatched ground truth labels\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n",
    "\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(y_true))\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_dir = './datasets/dataset/test/images'\n",
    "test_annotation_dir = './datasets/dataset/test/labels'\n",
    "\n",
    "images, annotations = load_images_and_annotations(test_image_dir, test_annotation_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 coccis, 116.5ms\n",
      "Speed: 3.0ms preprocess, 116.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'cocci', 1: 'healthy', 2: 'ncd', 3: 'salmo'}\n",
       " obb: None\n",
       " orig_img: array([[[ 70, 129, 169],\n",
       "         [ 70, 129, 169],\n",
       "         [ 71, 130, 170],\n",
       "         ...,\n",
       "         [ 34,  66, 101],\n",
       "         [ 37,  72, 106],\n",
       "         [ 47,  82, 116]],\n",
       " \n",
       "        [[ 54, 113, 153],\n",
       "         [ 54, 113, 153],\n",
       "         [ 53, 112, 152],\n",
       "         ...,\n",
       "         [ 43,  75, 110],\n",
       "         [ 37,  72, 106],\n",
       "         [ 38,  73, 107]],\n",
       " \n",
       "        [[ 49, 106, 145],\n",
       "         [ 46, 103, 142],\n",
       "         [ 53, 110, 149],\n",
       "         ...,\n",
       "         [ 35,  70, 104],\n",
       "         [ 41,  76, 110],\n",
       "         [ 43,  78, 112]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 23,  62, 100],\n",
       "         [ 11,  50,  88],\n",
       "         [ 51,  90, 128],\n",
       "         ...,\n",
       "         [ 89, 133, 170],\n",
       "         [ 97, 139, 174],\n",
       "         [106, 148, 183]],\n",
       " \n",
       "        [[ 70, 112, 149],\n",
       "         [ 63, 105, 142],\n",
       "         [ 75, 114, 152],\n",
       "         ...,\n",
       "         [ 98, 140, 177],\n",
       "         [103, 142, 180],\n",
       "         [105, 144, 182]],\n",
       " \n",
       "        [[ 92, 134, 171],\n",
       "         [ 98, 140, 177],\n",
       "         [ 95, 134, 172],\n",
       "         ...,\n",
       "         [121, 163, 200],\n",
       "         [124, 163, 201],\n",
       "         [127, 166, 204]]], dtype=uint8)\n",
       " orig_shape: (640, 640)\n",
       " path: 'image0.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict'\n",
       " speed: {'preprocess': 2.994060516357422, 'inference': 116.52469635009766, 'postprocess': 0.99945068359375}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.predict(images[0])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "cls: tensor([0., 0.])\n",
       "conf: tensor([0.8038, 0.5730])\n",
       "data: tensor([[1.1806e+02, 7.2237e+01, 5.1501e+02, 3.2753e+02, 8.0379e-01, 0.0000e+00],\n",
       "        [1.8935e+01, 3.3634e+02, 6.3241e+02, 5.9136e+02, 5.7296e-01, 0.0000e+00]])\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (640, 640)\n",
       "shape: torch.Size([2, 6])\n",
       "xywh: tensor([[316.5361, 199.8836, 396.9481, 255.2936],\n",
       "        [325.6731, 463.8467, 613.4768, 255.0232]])\n",
       "xywhn: tensor([[0.4946, 0.3123, 0.6202, 0.3989],\n",
       "        [0.5089, 0.7248, 0.9586, 0.3985]])\n",
       "xyxy: tensor([[118.0621,  72.2368, 515.0101, 327.5304],\n",
       "        [ 18.9347, 336.3351, 632.4115, 591.3583]])\n",
       "xyxyn: tensor([[0.1845, 0.1129, 0.8047, 0.5118],\n",
       "        [0.0296, 0.5255, 0.9881, 0.9240]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = run_inference(model, images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics(predictions, annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
